Which model performed worst and why might you have expected that model to have performed worst?

Unigram model preformed the worse! This was expected because it takes every word in isolation. Probability was simply a coin flip on each word.

Did smoothing help or hurt the model’s ‘performance’ when evaluated on this corpus? Why might that be?
